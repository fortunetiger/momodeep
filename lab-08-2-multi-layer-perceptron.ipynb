{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 08-2. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn Layers\n",
    "\n",
    "# layer 1\n",
    "w1 = torch.Tensor(2, 2).to(device)\n",
    "b1 = torch.Tensor(2).to(device)\n",
    "\n",
    "# layer 2\n",
    "w2 = torch.Tensor(2, 1).to(device)\n",
    "b2 = torch.Tensor(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # sigmoid function\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "    # return torch.div(torch.Tensor(1), torch.add(torch.Tensor(1.0), torch.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    # derivatice of the sigmoid function\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan\n",
      "100 nan\n",
      "200 nan\n",
      "300 nan\n",
      "400 nan\n",
      "500 nan\n",
      "600 nan\n",
      "700 nan\n",
      "800 nan\n",
      "900 nan\n",
      "1000 nan\n",
      "1100 nan\n",
      "1200 nan\n",
      "1300 nan\n",
      "1400 nan\n",
      "1500 nan\n",
      "1600 nan\n",
      "1700 nan\n",
      "1800 nan\n",
      "1900 nan\n",
      "2000 nan\n",
      "2100 nan\n",
      "2200 nan\n",
      "2300 nan\n",
      "2400 nan\n",
      "2500 nan\n",
      "2600 nan\n",
      "2700 nan\n",
      "2800 nan\n",
      "2900 nan\n",
      "3000 nan\n",
      "3100 nan\n",
      "3200 nan\n",
      "3300 nan\n",
      "3400 nan\n",
      "3500 nan\n",
      "3600 nan\n",
      "3700 nan\n",
      "3800 nan\n",
      "3900 nan\n",
      "4000 nan\n",
      "4100 nan\n",
      "4200 nan\n",
      "4300 nan\n",
      "4400 nan\n",
      "4500 nan\n",
      "4600 nan\n",
      "4700 nan\n",
      "4800 nan\n",
      "4900 nan\n",
      "5000 nan\n",
      "5100 nan\n",
      "5200 nan\n",
      "5300 nan\n",
      "5400 nan\n",
      "5500 nan\n",
      "5600 nan\n",
      "5700 nan\n",
      "5800 nan\n",
      "5900 nan\n",
      "6000 nan\n",
      "6100 nan\n",
      "6200 nan\n",
      "6300 nan\n",
      "6400 nan\n",
      "6500 nan\n",
      "6600 nan\n",
      "6700 nan\n",
      "6800 nan\n",
      "6900 nan\n",
      "7000 nan\n",
      "7100 nan\n",
      "7200 nan\n",
      "7300 nan\n",
      "7400 nan\n",
      "7500 nan\n",
      "7600 nan\n",
      "7700 nan\n",
      "7800 nan\n",
      "7900 nan\n",
      "8000 nan\n",
      "8100 nan\n",
      "8200 nan\n",
      "8300 nan\n",
      "8400 nan\n",
      "8500 nan\n",
      "8600 nan\n",
      "8700 nan\n",
      "8800 nan\n",
      "8900 nan\n",
      "9000 nan\n",
      "9100 nan\n",
      "9200 nan\n",
      "9300 nan\n",
      "9400 nan\n",
      "9500 nan\n",
      "9600 nan\n",
      "9700 nan\n",
      "9800 nan\n",
      "9900 nan\n",
      "10000 nan\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000+1):\n",
    "\n",
    "    # forward\n",
    "    l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "\n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
    "\n",
    "    # Backpropagation (chain rule)\n",
    "    # Loss derivative\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "\n",
    "    # layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "\n",
    "    # layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
    "\n",
    "    # weight update\n",
    "\n",
    "    learning_rate = 1\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XOR-nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn Layers\n",
    "linear1 = torch.nn.Linear(2, 2, bias=True).to(device)\n",
    "linear2 = torch.nn.Linear(2, 1, bias=True).to(device)\n",
    "sigmoid = torch.nn.Sigmoid().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7021235227584839\n",
      "100 0.6930285692214966\n",
      "200 0.6917076110839844\n",
      "300 0.6819795966148376\n",
      "400 0.6226609349250793\n",
      "500 0.5199195742607117\n",
      "600 0.3351201117038727\n",
      "700 0.11451005190610886\n",
      "800 0.05782149359583855\n",
      "900 0.037563323974609375\n",
      "1000 0.027556126937270164\n",
      "1100 0.021664217114448547\n",
      "1200 0.01780455932021141\n",
      "1300 0.015089327469468117\n",
      "1400 0.01307942159473896\n",
      "1500 0.011533737182617188\n",
      "1600 0.010309430770576\n",
      "1700 0.009316319599747658\n",
      "1800 0.008495084010064602\n",
      "1900 0.007805019151419401\n",
      "2000 0.007217212580144405\n",
      "2100 0.006710570305585861\n",
      "2200 0.006269552279263735\n",
      "2300 0.00588224409148097\n",
      "2400 0.005539457313716412\n",
      "2500 0.00523399980738759\n",
      "2600 0.004960056859999895\n",
      "2700 0.00471306499093771\n",
      "2800 0.0044892774894833565\n",
      "2900 0.00428556464612484\n",
      "3000 0.004099326673895121\n",
      "3100 0.003928428515791893\n",
      "3200 0.0037711120676249266\n",
      "3300 0.0036257554311305285\n",
      "3400 0.0034910980612039566\n",
      "3500 0.00336602795869112\n",
      "3600 0.0032494959887117147\n",
      "3700 0.003140691202133894\n",
      "3800 0.0030389237217605114\n",
      "3900 0.0029433993622660637\n",
      "4000 0.002853712532669306\n",
      "4100 0.0027692639268934727\n",
      "4200 0.002689619082957506\n",
      "4300 0.0026144031435251236\n",
      "4400 0.0025432417169213295\n",
      "4500 0.0024758498184382915\n",
      "4600 0.002411898458376527\n",
      "4700 0.0023511031176894903\n",
      "4800 0.0022933282889425755\n",
      "4900 0.002238230546936393\n",
      "5000 0.002185764256864786\n",
      "5100 0.0021356602665036917\n",
      "5200 0.0020877989009022713\n",
      "5300 0.002042015315964818\n",
      "5400 0.0019981749355793\n",
      "5500 0.001956143183633685\n",
      "5600 0.001915845088660717\n",
      "5700 0.0018772060284391046\n",
      "5800 0.0018400315893813968\n",
      "5900 0.0018043064046651125\n",
      "6000 0.00176997110247612\n",
      "6100 0.0017368609551340342\n",
      "6200 0.0017049610614776611\n",
      "6300 0.0016742413863539696\n",
      "6400 0.0016445375513285398\n",
      "6500 0.0016159540973603725\n",
      "6600 0.0015882670413702726\n",
      "6700 0.0015615359880030155\n",
      "6800 0.0015356863150373101\n",
      "6900 0.0015106431674212217\n",
      "7000 0.0014864213299006224\n",
      "7100 0.0014629762154072523\n",
      "7200 0.0014402330853044987\n",
      "7300 0.001418176805600524\n",
      "7400 0.0013968225102871656\n",
      "7500 0.0013760506408289075\n",
      "7600 0.0013558908831328154\n",
      "7700 0.001336343353614211\n",
      "7800 0.0013173335464671254\n",
      "7900 0.0012987866066396236\n",
      "8000 0.0012808367609977722\n",
      "8100 0.0012633497826755047\n",
      "8200 0.001246340572834015\n",
      "8300 0.0012297494104132056\n",
      "8400 0.0012136211153119802\n",
      "8500 0.0011978958500549197\n",
      "8600 0.001182573614642024\n",
      "8700 0.0011676396243274212\n",
      "8800 0.0011530638439580798\n",
      "8900 0.0011388761922717094\n",
      "9000 0.0011249722447246313\n",
      "9100 0.0011114412918686867\n",
      "9200 0.0010982388630509377\n",
      "9300 0.0010853349231183529\n",
      "9400 0.0010727294720709324\n",
      "9500 0.0010604225099086761\n",
      "9600 0.0010483693331480026\n",
      "9700 0.0010365997441112995\n",
      "9800 0.0010250689228996634\n",
      "9900 0.00101379188708961\n",
      "10000 0.0010027685202658176\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000+1):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XOR-nn-wide-deep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn Layers\n",
    "linear1 = torch.nn.Linear(2, 10, bias=True).to(device)\n",
    "linear2 = torch.nn.Linear(10, 10, bias=True).to(device)\n",
    "linear3 = torch.nn.Linear(10, 10, bias=True).to(device)\n",
    "linear4 = torch.nn.Linear(10, 1, bias=True).to(device)\n",
    "sigmoid = torch.nn.Sigmoid().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7082967758178711\n",
      "100 0.6931573748588562\n",
      "200 0.6931557655334473\n",
      "300 0.6931540966033936\n",
      "400 0.6931524276733398\n",
      "500 0.6931508779525757\n",
      "600 0.6931492686271667\n",
      "700 0.6931477785110474\n",
      "800 0.6931462287902832\n",
      "900 0.693144679069519\n",
      "1000 0.6931430697441101\n",
      "1100 0.6931414604187012\n",
      "1200 0.693139910697937\n",
      "1300 0.6931382417678833\n",
      "1400 0.6931365132331848\n",
      "1500 0.6931347846984863\n",
      "1600 0.6931329369544983\n",
      "1700 0.6931310892105103\n",
      "1800 0.6931290626525879\n",
      "1900 0.6931270360946655\n",
      "2000 0.6931248307228088\n",
      "2100 0.6931225061416626\n",
      "2200 0.693120002746582\n",
      "2300 0.6931173205375671\n",
      "2400 0.6931144595146179\n",
      "2500 0.6931113600730896\n",
      "2600 0.6931080222129822\n",
      "2700 0.6931042671203613\n",
      "2800 0.6931002140045166\n",
      "2900 0.6930956840515137\n",
      "3000 0.6930906772613525\n",
      "3100 0.6930851936340332\n",
      "3200 0.6930789351463318\n",
      "3300 0.6930717825889587\n",
      "3400 0.6930637359619141\n",
      "3500 0.6930544376373291\n",
      "3600 0.69304358959198\n",
      "3700 0.6930309534072876\n",
      "3800 0.6930159330368042\n",
      "3900 0.6929978132247925\n",
      "4000 0.6929758787155151\n",
      "4100 0.6929486989974976\n",
      "4200 0.6929144859313965\n",
      "4300 0.6928703784942627\n",
      "4400 0.6928118467330933\n",
      "4500 0.6927318572998047\n",
      "4600 0.6926178932189941\n",
      "4700 0.6924464106559753\n",
      "4800 0.6921695470809937\n",
      "4900 0.6916754841804504\n",
      "5000 0.6906507015228271\n",
      "5100 0.6879156827926636\n",
      "5200 0.6759141087532043\n",
      "5300 0.4996458888053894\n",
      "5400 0.02247067168354988\n",
      "5500 0.007267981767654419\n",
      "5600 0.004066308960318565\n",
      "5700 0.0027585935313254595\n",
      "5800 0.00206344248726964\n",
      "5900 0.001637074165046215\n",
      "6000 0.0013507662806659937\n",
      "6100 0.0011461854446679354\n",
      "6200 0.000993180088698864\n",
      "6300 0.0008747390238568187\n",
      "6400 0.0007805004133842885\n",
      "6500 0.0007038066396489739\n",
      "6600 0.0006403445731848478\n",
      "6700 0.000586890964768827\n",
      "6800 0.0005413421895354986\n",
      "6900 0.0005021465476602316\n",
      "7000 0.00046799133997410536\n",
      "7100 0.0004380562459118664\n",
      "7200 0.00041152085759676993\n",
      "7300 0.00038792286068201065\n",
      "7400 0.00036678503965958953\n",
      "7500 0.0003477792488411069\n",
      "7600 0.00033054762752726674\n",
      "7700 0.00031486654188483953\n",
      "7800 0.0003005719045177102\n",
      "7900 0.0002874848141800612\n",
      "8000 0.00027544129989109933\n",
      "8100 0.0002643369371071458\n",
      "8200 0.0002540077257435769\n",
      "8300 0.0002444984274916351\n",
      "8400 0.00023560028057545424\n",
      "8500 0.0002273431164212525\n",
      "8600 0.00021957787976134568\n",
      "8700 0.00021236414613667876\n",
      "8800 0.00020555290393531322\n",
      "8900 0.0001991739118238911\n",
      "9000 0.000193167565157637\n",
      "9100 0.00018747421563602984\n",
      "9200 0.0001820939069148153\n",
      "9300 0.00017704149649944156\n",
      "9400 0.0001722126908134669\n",
      "9500 0.00016766706539783627\n",
      "9600 0.00016334500105585903\n",
      "9700 0.00015918690769467503\n",
      "9800 0.00015526727656833827\n",
      "9900 0.00015151160187087953\n",
      "10000 0.00014794970047660172\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000+1):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
