{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ed3c58",
   "metadata": {},
   "source": [
    "# Lab 04-1. Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84303dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e30ed",
   "metadata": {},
   "source": [
    "*Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd1ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]\n",
    "                            ])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63825b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063f36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(x) 계산 with matmul()\n",
    "# - 더 간결하고, x의 길이가 바뀌어도 코드를 바꿀 필요가 없으며 더 빠르다.\n",
    "hypothesis = x_train.matmul(w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19912d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([w, b], lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ccbf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20  hypothesis :tensor([152.8022, 183.6741, 180.9683, 197.0706, 140.1009]), cost :1.618358850479126\n",
      "Epoch 1/20  hypothesis :tensor([152.8021, 183.6749, 180.9686, 197.0709, 140.1016]), cost :1.6176496744155884\n",
      "Epoch 2/20  hypothesis :tensor([152.8019, 183.6754, 180.9687, 197.0710, 140.1022]), cost :1.6169437170028687\n",
      "Epoch 3/20  hypothesis :tensor([152.8016, 183.6758, 180.9687, 197.0710, 140.1027]), cost :1.616214394569397\n",
      "Epoch 4/20  hypothesis :tensor([152.8012, 183.6762, 180.9686, 197.0710, 140.1032]), cost :1.6155126094818115\n",
      "Epoch 5/20  hypothesis :tensor([152.8008, 183.6765, 180.9686, 197.0710, 140.1036]), cost :1.6148197650909424\n",
      "Epoch 6/20  hypothesis :tensor([152.8004, 183.6768, 180.9684, 197.0709, 140.1041]), cost :1.614108681678772\n",
      "Epoch 7/20  hypothesis :tensor([152.8000, 183.6772, 180.9683, 197.0708, 140.1045]), cost :1.6133934259414673\n",
      "Epoch 8/20  hypothesis :tensor([152.7995, 183.6775, 180.9682, 197.0706, 140.1049]), cost :1.612701416015625\n",
      "Epoch 9/20  hypothesis :tensor([152.7991, 183.6778, 180.9681, 197.0705, 140.1053]), cost :1.611980676651001\n",
      "Epoch 10/20  hypothesis :tensor([152.7987, 183.6781, 180.9680, 197.0704, 140.1057]), cost :1.6112949848175049\n",
      "Epoch 11/20  hypothesis :tensor([152.7982, 183.6784, 180.9678, 197.0703, 140.1061]), cost :1.6106058359146118\n",
      "Epoch 12/20  hypothesis :tensor([152.7978, 183.6786, 180.9677, 197.0702, 140.1065]), cost :1.6098756790161133\n",
      "Epoch 13/20  hypothesis :tensor([152.7974, 183.6790, 180.9675, 197.0701, 140.1069]), cost :1.6091854572296143\n",
      "Epoch 14/20  hypothesis :tensor([152.7969, 183.6793, 180.9674, 197.0700, 140.1073]), cost :1.6084833145141602\n",
      "Epoch 15/20  hypothesis :tensor([152.7965, 183.6796, 180.9673, 197.0699, 140.1078]), cost :1.6077661514282227\n",
      "Epoch 16/20  hypothesis :tensor([152.7961, 183.6799, 180.9672, 197.0698, 140.1082]), cost :1.6070808172225952\n",
      "Epoch 17/20  hypothesis :tensor([152.7957, 183.6802, 180.9670, 197.0697, 140.1086]), cost :1.6063792705535889\n",
      "Epoch 18/20  hypothesis :tensor([152.7952, 183.6805, 180.9669, 197.0695, 140.1090]), cost :1.6056731939315796\n",
      "Epoch 19/20  hypothesis :tensor([152.7948, 183.6807, 180.9668, 197.0694, 140.1094]), cost :1.6049801111221313\n",
      "Epoch 20/20  hypothesis :tensor([152.7944, 183.6810, 180.9666, 197.0693, 140.1098]), cost :1.6042730808258057\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = x_train.matmul(w) + b\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch}/{nb_epochs}  hypothesis :{hypothesis.squeeze().detach()}, cost :{cost.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640a440",
   "metadata": {},
   "source": [
    "*nn.Modul*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1294221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3397eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32cbe6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20  hypothesis :tensor([-6.3386, -8.8591, -8.1792, -7.3521, -8.4331]), cost :32409.21875\n",
      "Epoch 1/20  hypothesis :tensor([63.9604, 75.6364, 75.0750, 83.3096, 56.0161]), cost :10162.603515625\n",
      "Epoch 2/20  hypothesis :tensor([103.3178, 122.9426, 121.6858, 134.0676,  92.0991]), cost :3189.46875\n",
      "Epoch 3/20  hypothesis :tensor([125.3523, 149.4278, 147.7814, 162.4851, 112.3010]), cost :1003.7599487304688\n",
      "Epoch 4/20  hypothesis :tensor([137.6882, 164.2561, 162.3913, 178.3949, 123.6116]), cost :318.65478515625\n",
      "Epoch 5/20  hypothesis :tensor([144.5943, 172.5582, 170.5707, 187.3021, 129.9444]), cost :103.90892028808594\n",
      "Epoch 6/20  hypothesis :tensor([148.4604, 177.2065, 175.1499, 192.2888, 133.4902]), cost :36.59600067138672\n",
      "Epoch 7/20  hypothesis :tensor([150.6246, 179.8091, 177.7136, 195.0806, 135.4757]), cost :15.495219230651855\n",
      "Epoch 8/20  hypothesis :tensor([151.8359, 181.2665, 179.1488, 196.6435, 136.5876]), cost :8.879684448242188\n",
      "Epoch 9/20  hypothesis :tensor([152.5137, 182.0826, 179.9522, 197.5185, 137.2105]), cost :6.804457664489746\n",
      "Epoch 10/20  hypothesis :tensor([152.8929, 182.5398, 180.4019, 198.0082, 137.5595]), cost :6.152392864227295\n",
      "Epoch 11/20  hypothesis :tensor([153.1048, 182.7960, 180.6536, 198.2823, 137.7553]), cost :5.946381568908691\n",
      "Epoch 12/20  hypothesis :tensor([153.2231, 182.9397, 180.7944, 198.4357, 137.8652]), cost :5.880166053771973\n",
      "Epoch 13/20  hypothesis :tensor([153.2890, 183.0203, 180.8731, 198.5214, 137.9271]), cost :5.857810020446777\n",
      "Epoch 14/20  hypothesis :tensor([153.3256, 183.0657, 180.9171, 198.5693, 137.9621]), cost :5.849177837371826\n",
      "Epoch 15/20  hypothesis :tensor([153.3457, 183.0914, 180.9416, 198.5960, 137.9819]), cost :5.844888687133789\n",
      "Epoch 16/20  hypothesis :tensor([153.3566, 183.1060, 180.9552, 198.6109, 137.9934]), cost :5.84190559387207\n",
      "Epoch 17/20  hypothesis :tensor([153.3624, 183.1144, 180.9628, 198.6191, 138.0002]), cost :5.839405536651611\n",
      "Epoch 18/20  hypothesis :tensor([153.3653, 183.1193, 180.9669, 198.6236, 138.0043]), cost :5.836984634399414\n",
      "Epoch 19/20  hypothesis :tensor([153.3666, 183.1223, 180.9691, 198.6261, 138.0069]), cost :5.834606170654297\n",
      "Epoch 20/20  hypothesis :tensor([153.3670, 183.1243, 180.9702, 198.6273, 138.0087]), cost :5.832254409790039\n"
     ]
    }
   ],
   "source": [
    "model = MultivariateLinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    "    \n",
    "    # cost로 H(x)개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch}/{nb_epochs}  hypothesis :{hypothesis.squeeze().detach()}, cost :{cost.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
